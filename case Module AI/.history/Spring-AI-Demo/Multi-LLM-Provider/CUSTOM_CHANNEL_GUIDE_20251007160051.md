# è‡ªå®šä¹‰æ¸ é“ä½¿ç”¨æŒ‡å—

## ğŸ¯ ä»€ä¹ˆæ˜¯è‡ªå®šä¹‰æ¸ é“ï¼Ÿ

è‡ªå®šä¹‰æ¸ é“å…è®¸ä½ ä½¿ç”¨ä»»ä½•å…¼å®¹ OpenAI API æ ¼å¼çš„æœåŠ¡ï¼Œåªéœ€æä¾›ï¼š
- **Base URL**ï¼šAPI æœåŠ¡çš„åŸºç¡€åœ°å€
- **API Token**ï¼šè®¤è¯ä»¤ç‰Œ
- **Model**ï¼ˆå¯é€‰ï¼‰ï¼šæ¨¡å‹åç§°

## ğŸš€ ä½¿ç”¨åœºæ™¯

### 1. ç¬¬ä¸‰æ–¹ OpenAI API ä»£ç†
è®¸å¤šæœåŠ¡æä¾› OpenAI API çš„ä»£ç†æˆ–é•œåƒæœåŠ¡ï¼š

```bash
curl -X POST http://localhost:8080/api/llm/custom/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ä½ å¥½",
    "baseUrl": "https://your-proxy.com/v1",
    "apiToken": "your-token",
    "model": "gpt-3.5-turbo"
  }'
```

### 2. è‡ªå»º LLM æœåŠ¡
å¦‚æœä½ éƒ¨ç½²äº†å…¼å®¹ OpenAI API çš„æœ¬åœ°æœåŠ¡ï¼ˆå¦‚ vLLMã€FastChatï¼‰ï¼š

```bash
curl -X POST http://localhost:8080/api/llm/custom/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
    "baseUrl": "http://localhost:8000/v1",
    "apiToken": "dummy-token",
    "model": "vicuna-7b"
  }'
```

### 3. å…¶ä»–äº‘æœåŠ¡å•†
ä½¿ç”¨å…¶ä»–äº‘æœåŠ¡å•†æä¾›çš„ OpenAI å…¼å®¹æ¥å£ï¼š

```bash
# ç¤ºä¾‹ï¼šæŸäº‘æœåŠ¡å•†
curl -X POST http://localhost:8080/api/llm/custom/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    "baseUrl": "https://api.cloud-provider.com/v1",
    "apiToken": "your-cloud-token",
    "model": "gpt-3.5-turbo"
  }'
```

### 4. æµ‹è¯•ä¸åŒçš„ API ç«¯ç‚¹
å¿«é€Ÿæµ‹è¯•å’Œåˆ‡æ¢ä¸åŒçš„ API æœåŠ¡ï¼š

```bash
# æµ‹è¯•ç«¯ç‚¹ A
curl -X POST http://localhost:8080/api/llm/custom/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "æµ‹è¯•æ¶ˆæ¯",
    "baseUrl": "https://api-a.example.com/v1",
    "apiToken": "token-a",
    "model": "gpt-3.5-turbo"
  }'

# æµ‹è¯•ç«¯ç‚¹ B
curl -X POST http://localhost:8080/api/llm/custom/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "æµ‹è¯•æ¶ˆæ¯",
    "baseUrl": "https://api-b.example.com/v1",
    "apiToken": "token-b",
    "model": "gpt-4"
  }'
```

## ğŸ“¡ API æ¥å£

### POST /api/llm/custom/chat
æ™®é€šå¯¹è¯æ¥å£

**è¯·æ±‚å‚æ•°**ï¼š
```json
{
  "message": "ç”¨æˆ·æ¶ˆæ¯",
  "baseUrl": "API åŸºç¡€åœ°å€ï¼ˆå¿…å¡«ï¼‰",
  "apiToken": "API ä»¤ç‰Œï¼ˆå¿…å¡«ï¼‰",
  "model": "æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ gpt-3.5-turboï¼‰"
}
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "provider": "Custom Channel",
  "model": "gpt-3.5-turbo",
  "response": "AI çš„å›å¤å†…å®¹...",
  "duration": 1234
}
```

### POST /api/llm/custom/stream
æµå¼å¯¹è¯æ¥å£

**è¯·æ±‚å‚æ•°**ï¼šåŒä¸Š

**å“åº”æ ¼å¼**ï¼šServer-Sent Events (SSE)
```
data: ä½ å¥½
data: ï¼
data: æˆ‘æ˜¯
data: AI
...
```

## ğŸ¨ ä½¿ç”¨ HTML æ¼”ç¤ºé¡µé¢

1. æ‰“å¼€ `demo.html` æ–‡ä»¶
2. æ‰¾åˆ°"è‡ªå®šä¹‰æ¸ é“"éƒ¨åˆ†
3. å¡«å†™ä»¥ä¸‹ä¿¡æ¯ï¼š
   - **Base URL**ï¼šä¾‹å¦‚ `https://api.openai.com/v1`
   - **API Token**ï¼šä½ çš„ API å¯†é’¥
   - **æ¨¡å‹åç§°**ï¼šä¾‹å¦‚ `gpt-3.5-turbo`ï¼ˆå¯é€‰ï¼‰
   - **è¾“å…¥æ¶ˆæ¯**ï¼šä½ æƒ³é—®çš„é—®é¢˜
4. ç‚¹å‡»"æ™®é€šå¯¹è¯"æˆ–"æµå¼å¯¹è¯"æŒ‰é’®

## ğŸ’¡ å¸¸è§é…ç½®ç¤ºä¾‹

### OpenAI å®˜æ–¹
```json
{
  "baseUrl": "https://api.openai.com/v1",
  "apiToken": "sk-xxx",
  "model": "gpt-3.5-turbo"
}
```

### æœ¬åœ° vLLM æœåŠ¡
```json
{
  "baseUrl": "http://localhost:8000/v1",
  "apiToken": "dummy",
  "model": "meta-llama/Llama-2-7b-chat-hf"
}
```

### æœ¬åœ° Ollamaï¼ˆé€šè¿‡ OpenAI å…¼å®¹æ¥å£ï¼‰
```json
{
  "baseUrl": "http://localhost:11434/v1",
  "apiToken": "ollama",
  "model": "llama2"
}
```

### FastChat æœåŠ¡
```json
{
  "baseUrl": "http://localhost:8000/v1",
  "apiToken": "dummy",
  "model": "vicuna-7b"
}
```

## ğŸ” å®‰å…¨å»ºè®®

1. **ä¸è¦åœ¨å‰ç«¯ç¡¬ç¼–ç  API Token**
   - åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œåº”è¯¥é€šè¿‡åç«¯ä»£ç†è¯·æ±‚
   - ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡

2. **éªŒè¯ Base URL**
   - ç¡®ä¿ Base URL æ˜¯å¯ä¿¡çš„
   - ä½¿ç”¨ HTTPS åŠ å¯†ä¼ è¾“

3. **é™æµå’Œç›‘æ§**
   - å®ç°è¯·æ±‚é™æµ
   - ç›‘æ§ API ä½¿ç”¨æƒ…å†µå’Œæˆæœ¬

4. **é”™è¯¯å¤„ç†**
   - å¦¥å–„å¤„ç†ç½‘ç»œé”™è¯¯
   - æä¾›å‹å¥½çš„é”™è¯¯æç¤º

## ğŸ› ï¸ æŠ€æœ¯å®ç°

è‡ªå®šä¹‰æ¸ é“ä½¿ç”¨ Spring AI çš„ `OpenAiApi` ç±»ï¼Œæ”¯æŒè‡ªå®šä¹‰ Base URLï¼š

```java
// åˆ›å»ºè‡ªå®šä¹‰çš„ OpenAI API å®¢æˆ·ç«¯
OpenAiApi openAiApi = new OpenAiApi(baseUrl, apiToken);

// åˆ›å»ºèŠå¤©æ¨¡å‹
OpenAiChatModel chatModel = new OpenAiChatModel(openAiApi, 
    OpenAiChatOptions.builder()
        .withModel(model)
        .withTemperature(0.7)
        .build());

// åˆ›å»º ChatClient å¹¶æ‰§è¡Œå¯¹è¯
ChatClient chatClient = ChatClient.builder(chatModel).build();
```

## ğŸ”— å…¼å®¹çš„æœåŠ¡

ä»¥ä¸‹æœåŠ¡æä¾› OpenAI å…¼å®¹çš„ APIï¼š

- **vLLM** - é«˜æ€§èƒ½ LLM æ¨ç†å¼•æ“
- **FastChat** - å¼€æºèŠå¤©æœºå™¨äººå¹³å°
- **Text Generation WebUI** - æœ¬åœ° LLM ç•Œé¢
- **LocalAI** - OpenAI çš„æœ¬åœ°æ›¿ä»£å“
- **Ollama**ï¼ˆé€šè¿‡ OpenAI å…¼å®¹å±‚ï¼‰
- å„ç§äº‘æœåŠ¡å•†çš„ OpenAI å…¼å®¹æ¥å£

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **Base URL æ ¼å¼**
   - å¿…é¡»åŒ…å«å®Œæ•´çš„åè®®ï¼ˆhttp:// æˆ– https://ï¼‰
   - é€šå¸¸ä»¥ `/v1` ç»“å°¾
   - ä¾‹å¦‚ï¼š`https://api.openai.com/v1`

2. **æ¨¡å‹åç§°**
   - ä¸åŒæœåŠ¡æ”¯æŒçš„æ¨¡å‹åç§°å¯èƒ½ä¸åŒ
   - å¦‚æœä¸ç¡®å®šï¼Œå¯ä»¥ç•™ç©ºä½¿ç”¨é»˜è®¤å€¼

3. **API Token**
   - æŸäº›æœ¬åœ°æœåŠ¡å¯èƒ½ä¸éœ€è¦çœŸå®çš„ token
   - å¯ä»¥ä½¿ç”¨ "dummy" æˆ–ä»»æ„å­—ç¬¦ä¸²

4. **ç½‘ç»œè¿æ¥**
   - ç¡®ä¿æœåŠ¡å™¨å¯ä»¥è®¿é—®æŒ‡å®šçš„ Base URL
   - æ£€æŸ¥é˜²ç«å¢™å’Œç½‘ç»œé…ç½®

## ğŸ“ æœ€ä½³å®è·µ

1. **ç¯å¢ƒéš”ç¦»**
   - å¼€å‘ç¯å¢ƒä½¿ç”¨æµ‹è¯• token
   - ç”Ÿäº§ç¯å¢ƒä½¿ç”¨æ­£å¼ token

2. **é…ç½®ç®¡ç†**
   - å°†å¸¸ç”¨é…ç½®ä¿å­˜ä¸ºé¢„è®¾
   - ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†å¤šä¸ªæ¸ é“

3. **ç›‘æ§å’Œæ—¥å¿—**
   - è®°å½•æ¯æ¬¡ API è°ƒç”¨
   - ç›‘æ§å“åº”æ—¶é—´å’Œé”™è¯¯ç‡

4. **æˆæœ¬æ§åˆ¶**
   - è®¾ç½®ä½¿ç”¨é™é¢
   - å®šæœŸå®¡æŸ¥ API ä½¿ç”¨æƒ…å†µ

## ğŸš€ æ‰©å±•åŠŸèƒ½

åŸºäºè‡ªå®šä¹‰æ¸ é“ï¼Œä½ å¯ä»¥å®ç°ï¼š

- **å¤šæ¸ é“è´Ÿè½½å‡è¡¡**ï¼šåœ¨å¤šä¸ª API ç«¯ç‚¹ä¹‹é—´åˆ†é…è¯·æ±‚
- **è‡ªåŠ¨æ•…éšœè½¬ç§»**ï¼šä¸»æ¸ é“å¤±è´¥æ—¶åˆ‡æ¢åˆ°å¤‡ç”¨æ¸ é“
- **æˆæœ¬ä¼˜åŒ–**ï¼šæ ¹æ®ä»·æ ¼é€‰æ‹©æœ€ä¼˜æ¸ é“
- **A/B æµ‹è¯•**ï¼šå¯¹æ¯”ä¸åŒæœåŠ¡çš„æ•ˆæœ
- **æ¸ é“ç®¡ç†ç•Œé¢**ï¼šå¯è§†åŒ–ç®¡ç†å¤šä¸ªè‡ªå®šä¹‰æ¸ é“

## ğŸ“š å‚è€ƒèµ„æ–™

- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs/api-reference)
- [vLLM æ–‡æ¡£](https://docs.vllm.ai/)
- [FastChat æ–‡æ¡£](https://github.com/lm-sys/FastChat)
- [Spring AI æ–‡æ¡£](https://docs.spring.io/spring-ai/reference/)
