# æ—¥å¿—é…ç½®æŒ‡å—

## ğŸ“‹ æ—¥å¿—çº§åˆ«è¯´æ˜

é¡¹ç›®ä½¿ç”¨ SLF4J + Logback è¿›è¡Œæ—¥å¿—è®°å½•ï¼ŒåŒ…å«ä»¥ä¸‹çº§åˆ«ï¼š

### æ—¥å¿—çº§åˆ«

| çº§åˆ« | è¯´æ˜ | ä½¿ç”¨åœºæ™¯ |
|------|------|----------|
| **TRACE** | æœ€è¯¦ç»†çš„æ—¥å¿— | æµå¼å“åº”çš„æ¯ä¸ª chunk |
| **DEBUG** | è°ƒè¯•ä¿¡æ¯ | API Token å‰ç¼€ã€å“åº”é¢„è§ˆã€è¯¦ç»†æ­¥éª¤ |
| **INFO** | ä¸€èˆ¬ä¿¡æ¯ | è¯·æ±‚å¼€å§‹ã€å®Œæˆã€è€—æ—¶ç»Ÿè®¡ |
| **WARN** | è­¦å‘Šä¿¡æ¯ | æ½œåœ¨é—®é¢˜ |
| **ERROR** | é”™è¯¯ä¿¡æ¯ | å¼‚å¸¸å’Œå¤±è´¥æƒ…å†µ |

## ğŸ¯ æ—¥å¿—å†…å®¹

### Controller å±‚æ—¥å¿—

#### 1. è¯·æ±‚å¼€å§‹æ—¥å¿—
```
INFO  - === OpenAI Chat Request ===
INFO  - Message: ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±
```

#### 2. è¯·æ±‚å®Œæˆæ—¥å¿—
```
INFO  - OpenAI chat completed successfully in 1234ms
DEBUG - Response preview: ä½ å¥½ï¼æˆ‘æ˜¯ ChatGPT...
```

#### 3. æµå¼è¯·æ±‚æ—¥å¿—
```
INFO  - === OpenAI Stream Chat Request ===
INFO  - Message: è¯·ä»‹ç» Spring AI
INFO  - OpenAI stream started
INFO  - OpenAI stream completed
```

#### 4. è‡ªå®šä¹‰æ¸ é“æ—¥å¿—
```
INFO  - === Custom Channel Chat Request ===
INFO  - Message: ä½ å¥½
INFO  - BaseURL: https://api.openai.com/v1
INFO  - Model: gpt-3.5-turbo
DEBUG - API Token: sk-proj-ab***
INFO  - Custom channel chat completed successfully in 2345ms
DEBUG - Response preview: ä½ å¥½ï¼æˆ‘æ˜¯...
```

#### 5. é”™è¯¯æ—¥å¿—
```
ERROR - OpenAI chat failed: Connection timeout
ERROR - Stack trace...
```

### Service å±‚æ—¥å¿—

#### 1. CustomChannelService æ™®é€šå¯¹è¯
```
INFO  - Starting custom channel chat
INFO  - BaseURL: https://api.openai.com/v1
INFO  - Model: gpt-3.5-turbo
INFO  - Message length: 50 characters
DEBUG - Message content: ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±
DEBUG - Creating OpenAI API client with custom baseUrl
DEBUG - Creating chat model with options - Model: gpt-3.5-turbo, Temperature: 0.7
DEBUG - Building ChatClient and executing prompt
INFO  - Custom channel chat completed successfully
INFO  - Response time: 1234ms
INFO  - Response length: 200 characters
DEBUG - Response preview: ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ª AI åŠ©æ‰‹...
```

#### 2. CustomChannelService æµå¼å¯¹è¯
```
INFO  - Starting custom channel stream chat
INFO  - BaseURL: https://api.openai.com/v1
INFO  - Model: gpt-3.5-turbo
INFO  - Message length: 50 characters
DEBUG - Message content: è¯·ä»‹ç» Spring AI
DEBUG - Creating OpenAI API client with custom baseUrl for streaming
DEBUG - Creating chat model for streaming - Model: gpt-3.5-turbo, Temperature: 0.7
DEBUG - Building ChatClient and starting stream
TRACE - Received chunk: Spring
TRACE - Received chunk:  AI
TRACE - Received chunk:  æ˜¯
INFO  - Custom channel stream completed successfully
INFO  - Stream duration: 3456ms
INFO  - Total response length: 500 characters
DEBUG - Full response: Spring AI æ˜¯ä¸€ä¸ªç”¨äºæ„å»º AI åº”ç”¨çš„æ¡†æ¶...
```

#### 3. é”™è¯¯æ—¥å¿—
```
ERROR - Custom channel chat failed
ERROR - Error details - BaseURL: https://api.example.com/v1, Model: gpt-3.5-turbo
ERROR - Error message: Connection refused
ERROR - Stack trace...
```

## âš™ï¸ é…ç½®æ—¥å¿—çº§åˆ«

### åœ¨ application.yml ä¸­é…ç½®

```yaml
logging:
  level:
    # æ ¹æ—¥å¿—çº§åˆ«
    root: INFO
    
    # Spring AI æ¡†æ¶æ—¥å¿—
    org.springframework.ai: DEBUG
    
    # é¡¹ç›®æ—¥å¿—
    com.example.multillm: INFO
    
    # Controller å±‚æ—¥å¿—
    com.example.multillm.controller: INFO
    
    # Service å±‚æ—¥å¿—
    com.example.multillm.service: INFO
    
    # æŸ¥çœ‹è¯¦ç»†çš„ API è°ƒç”¨ï¼ˆåŒ…æ‹¬ chunkï¼‰
    com.example.multillm.service.CustomChannelService: DEBUG
```

### é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®

```bash
# Linux/Mac
export LOGGING_LEVEL_COM_EXAMPLE_MULTILLM=DEBUG

# Windows
set LOGGING_LEVEL_COM_EXAMPLE_MULTILLM=DEBUG
```

### é€šè¿‡å‘½ä»¤è¡Œå‚æ•°é…ç½®

```bash
mvn spring-boot:run -Dlogging.level.com.example.multillm=DEBUG
```

## ğŸ“Š æ¨èé…ç½®

### å¼€å‘ç¯å¢ƒ
```yaml
logging:
  level:
    root: INFO
    com.example.multillm: DEBUG
    org.springframework.ai: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
```

### ç”Ÿäº§ç¯å¢ƒ
```yaml
logging:
  level:
    root: WARN
    com.example.multillm: INFO
    org.springframework.ai: WARN
  file:
    name: logs/multi-llm-provider.log
    max-size: 10MB
    max-history: 30
  pattern:
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
```

### è°ƒè¯•æ¨¡å¼ï¼ˆæŸ¥çœ‹æ‰€æœ‰ç»†èŠ‚ï¼‰
```yaml
logging:
  level:
    root: INFO
    com.example.multillm: TRACE
    org.springframework.ai: DEBUG
```

## ğŸ” æ—¥å¿—åˆ†æç¤ºä¾‹

### 1. æŸ¥çœ‹è¯·æ±‚è€—æ—¶
```bash
grep "completed successfully" logs/multi-llm-provider.log | grep "ms"
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
2025-01-07 10:30:15 INFO  - OpenAI chat completed successfully in 1234ms
2025-01-07 10:31:20 INFO  - Custom channel chat completed successfully in 2345ms
```

### 2. æŸ¥çœ‹é”™è¯¯æ—¥å¿—
```bash
grep "ERROR" logs/multi-llm-provider.log
```

### 3. æŸ¥çœ‹ç‰¹å®šæ¸ é“çš„è¯·æ±‚
```bash
grep "Custom Channel" logs/multi-llm-provider.log
```

### 4. ç»Ÿè®¡å„æ¸ é“ä½¿ç”¨æ¬¡æ•°
```bash
grep "Chat Request ===" logs/multi-llm-provider.log | cut -d' ' -f5 | sort | uniq -c
```

## ğŸ“ æ—¥å¿—æœ€ä½³å®è·µ

### 1. æ•æ„Ÿä¿¡æ¯ä¿æŠ¤
- âœ… API Token åªè®°å½•å‰ 10 ä¸ªå­—ç¬¦
- âœ… ä½¿ç”¨ DEBUG çº§åˆ«è®°å½•æ•æ„Ÿä¿¡æ¯
- âœ… ç”Ÿäº§ç¯å¢ƒä¸è¾“å‡º DEBUG æ—¥å¿—

```java
log.debug("API Token: {}***", apiToken.substring(0, Math.min(10, apiToken.length())));
```

### 2. æ€§èƒ½ç›‘æ§
- âœ… è®°å½•æ¯ä¸ªè¯·æ±‚çš„è€—æ—¶
- âœ… è®°å½•å“åº”é•¿åº¦
- âœ… è®°å½•æµå¼å“åº”çš„æ€»æ—¶é•¿

```java
long duration = System.currentTimeMillis() - start;
log.info("Request completed in {}ms", duration);
```

### 3. é”™è¯¯è¿½è¸ª
- âœ… è®°å½•å®Œæ•´çš„å¼‚å¸¸å †æ ˆ
- âœ… è®°å½•è¯·æ±‚ä¸Šä¸‹æ–‡ï¼ˆBaseURLã€Model ç­‰ï¼‰
- âœ… æä¾›æ¸…æ™°çš„é”™è¯¯æ¶ˆæ¯

```java
log.error("Custom channel chat failed", e);
log.error("Error details - BaseURL: {}, Model: {}", baseUrl, model);
```

### 4. è°ƒè¯•ä¿¡æ¯
- âœ… è®°å½•å…³é”®æ­¥éª¤
- âœ… è®°å½•å“åº”é¢„è§ˆï¼ˆå‰ 100-200 å­—ç¬¦ï¼‰
- âœ… ä½¿ç”¨ TRACE çº§åˆ«è®°å½•æµå¼ chunk

```java
log.debug("Response preview: {}", response.substring(0, Math.min(100, response.length())));
```

## ğŸ¨ æ—¥å¿—è¾“å‡ºæ ¼å¼

### æ§åˆ¶å°è¾“å‡º
```
2025-01-07 10:30:15 [http-nio-8080-exec-1] INFO  c.e.m.controller.LLMController - === OpenAI Chat Request ===
2025-01-07 10:30:15 [http-nio-8080-exec-1] INFO  c.e.m.controller.LLMController - Message: ä½ å¥½
2025-01-07 10:30:16 [http-nio-8080-exec-1] INFO  c.e.m.controller.LLMController - OpenAI chat completed successfully in 1234ms
```

### æ–‡ä»¶è¾“å‡ºï¼ˆJSON æ ¼å¼ï¼‰
```json
{
  "timestamp": "2025-01-07T10:30:15.123Z",
  "level": "INFO",
  "thread": "http-nio-8080-exec-1",
  "logger": "com.example.multillm.controller.LLMController",
  "message": "OpenAI chat completed successfully in 1234ms",
  "context": {
    "provider": "OpenAI",
    "duration": 1234
  }
}
```

## ğŸ”§ è‡ªå®šä¹‰æ—¥å¿—é…ç½®

### åˆ›å»º logback-spring.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- æ§åˆ¶å°è¾“å‡º -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- æ–‡ä»¶è¾“å‡º -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/multi-llm-provider.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/multi-llm-provider.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- é”™è¯¯æ—¥å¿—å•ç‹¬è¾“å‡º -->
    <appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/error.log</file>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/error.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- é¡¹ç›®æ—¥å¿— -->
    <logger name="com.example.multillm" level="INFO"/>
    
    <!-- Spring AI æ—¥å¿— -->
    <logger name="org.springframework.ai" level="DEBUG"/>
    
    <!-- æ ¹æ—¥å¿— -->
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="FILE"/>
        <appender-ref ref="ERROR_FILE"/>
    </root>
</configuration>
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [Logback å®˜æ–¹æ–‡æ¡£](https://logback.qos.ch/manual/)
- [Spring Boot æ—¥å¿—é…ç½®](https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.logging)
- [SLF4J æ–‡æ¡£](http://www.slf4j.org/manual.html)

## ğŸ’¡ æç¤º

1. **å¼€å‘æ—¶ä½¿ç”¨ DEBUG çº§åˆ«**ï¼Œå¯ä»¥çœ‹åˆ°è¯¦ç»†çš„æ‰§è¡Œè¿‡ç¨‹
2. **ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ INFO çº§åˆ«**ï¼Œå‡å°‘æ—¥å¿—é‡
3. **é‡åˆ°é—®é¢˜æ—¶ä¸´æ—¶å¼€å¯ TRACE çº§åˆ«**ï¼ŒæŸ¥çœ‹æµå¼å“åº”çš„æ¯ä¸ª chunk
4. **å®šæœŸæ¸…ç†æ—¥å¿—æ–‡ä»¶**ï¼Œé¿å…å ç”¨è¿‡å¤šç£ç›˜ç©ºé—´
5. **ä½¿ç”¨æ—¥å¿—åˆ†æå·¥å…·**ï¼ˆå¦‚ ELK Stackï¼‰è¿›è¡Œæ—¥å¿—èšåˆå’Œåˆ†æ
